{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2ea2644-41cc-4942-a237-85dbfe645aaf",
   "metadata": {},
   "source": [
    "Consider following code to answer further questions:\n",
    "import pandas as pd\n",
    "course_name = [‘Data Science’, ‘Machine Learning’, ‘Big Data’, ‘Data Engineer’]\n",
    "duration = [2,3,6,4]\n",
    "df = pd.DataFrame(data = {‘course_name’ : course_name, ‘duration’ : duration})\n",
    "Q1. Write a code to print the data present in the second row of the dataframe, df."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264fc153-93d7-4925-bb0e-8588f19f5187",
   "metadata": {},
   "source": [
    "we can use the '.iloc[ ]' indexer to access rows by their integer index.The second row would have an index of 1 since indexing starts from 0 .Here's how we can print the data present in the second row of the DataFrame 'df'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f915da38-4793-473e-a48b-da5a6dc89e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "course_name     Machine Learning \n",
      "duration                        3\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "course_name =['Data Science ', 'Machine Learning ','Big Data', 'Data Engineer']\n",
    "duration =[2,3,6,4]\n",
    "df= pd.DataFrame (data={'course_name ':course_name, 'duration ':duration })\n",
    "\n",
    "print(df.iloc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812b585d-891f-4829-a781-9a4555c8c88b",
   "metadata": {},
   "source": [
    "Q2. What is the difference between the functions loc and iloc in pandas.DataFrame?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecef029-4a03-400e-808f-7e83d6de831c",
   "metadata": {},
   "source": [
    "The main difference between the functions 'loc' and 'iloc' in a 'pandas .DataFrame' lies in how they are used to access data:\n",
    "\n",
    "### 1.'loc':\n",
    "- 'loc' is primarily label-based .It is used to access data using labels or indexes along the index or column axis .\n",
    "- It allows you to access a group of rows and columns by labels or a boolean array .\n",
    "- When using 'loc' , the indexing is inclusive , meaning both the start and stop labels are included .\n",
    "- It accepts label-based indexing .This means you use column and row labels to index into the DataFrame.\n",
    "\n",
    "### 'iloc':\n",
    "- 'iloc' is primarily integer-based .It is used for selecting databased on its integer location.\n",
    "- It allows you to access a group of rows and columns by integer positions .\n",
    "- When using 'iloc', the indexing is exclusive for the end value, similar to python slicing.\n",
    "- It accepts integer-based indexing .This means we can use integer positions to index into the DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6cb3b81-7729-4c0f-898c-0b4b9922d94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A   B\n",
      "b  2  20\n",
      "c  3  30\n",
      "d  4  40\n",
      "   A   B\n",
      "b  2  20\n",
      "c  3  30\n",
      "d  4  40\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.DataFrame({'A':[1,2,3,4,5],'B':[10,20,30,40,50]},\n",
    "                 index=['a','b','c','d','e'])\n",
    "\n",
    "print(df.loc['b':'d','A':'B'])\n",
    "print(df.iloc[1:4, 0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f023b356-abaf-4582-9153-865ea0e93533",
   "metadata": {},
   "source": [
    "In the first print statement , 'df.loc'['b':'d','A':'B'] , we are using labels ('b' to 'd') and column names ('A'to 'B')to slice the DataFrame .In the second print statement,df.iloc[1:4, 0:2] , we are using integer position position (0 to 1 ) to sclice the DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bc06e6-41fc-4f8d-a56d-19e1abaa841b",
   "metadata": {
    "tags": []
   },
   "source": [
    "Q3.Reindex the given dataframe using a variable, reindex = [3,0,1,2] and store it in the variable, new_df\n",
    "then find the output for both new_df.loc[2] and new_df.iloc[2]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a759163-0751-4504-abb2-97aa1cfd357d",
   "metadata": {},
   "source": [
    "To reindex the DataFrame using the specified list [3, 0, 1, 2], we can use the reindex() function in pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ffbe547-3864-4b45-b04f-777480c8f436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output for new_df.loc[2]:\n",
      "A     3\n",
      "B    30\n",
      "Name: 2, dtype: int64\n",
      "\n",
      " Output for new_df_.iloc[2]:\n",
      "A     2\n",
      "B    20\n",
      "Name: 1, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df = pd.DataFrame({'A':[1,2,3,4],\n",
    "                  'B':[10,20,30,40]})\n",
    "reindex =[3, 0 , 1,2 ]\n",
    "new_df = df.reindex(reindex )\n",
    "print(\"Output for new_df.loc[2]:\")\n",
    "print(new_df.loc[2])\n",
    "\n",
    "print(\"\\n Output for new_df_.iloc[2]:\")\n",
    "print(new_df.iloc[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f38914d-43cd-4199-8c37-41e5d5c7c34c",
   "metadata": {},
   "source": [
    "- 'new_df.loc[2]'will return the row with index label '2' after reindexing.\n",
    "- 'new_df.iloc[2]'will return the row with the index position '2'after reindexing.\n",
    "\n",
    "If there are differences betweeen the outputs , it means that the insex labels have been changed by reindexing process .'loc[]' uses the index labels , while 'iloc[]' uses the intefge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee6840b-ecc9-4193-ac68-3089a32b6179",
   "metadata": {},
   "source": [
    "Q4. Write a code to find the following statistical measurements for the above dataframe df1:\n",
    "\n",
    "\n",
    "(i) mean of each and every column present in the dataframe.\n",
    "\n",
    "\n",
    "(ii) standard deviation of column, ‘column_2’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d10e61b-8e66-4f72-a7a6-403689ec32f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of each column:\n",
      "column_1    0.581028\n",
      "column_2    0.597451\n",
      "column_3    0.489292\n",
      "column_4    0.670694\n",
      "column_5    0.524257\n",
      "column_6    0.499103\n",
      "dtype: float64\n",
      "\n",
      "Standard deviation of column_2:\n",
      "0.39298561699135554\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "columns = ['column_1', 'column_2', 'column_3', 'column_4', 'column_5', 'column_6']\n",
    "indices = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "df1 = pd.DataFrame(np.random.rand(6, 6), columns=columns, index=indices)\n",
    "\n",
    "means = df1.mean()\n",
    "print(\"Mean of each column:\")\n",
    "print(means)\n",
    "\n",
    "std_dev_column_2 = df1['column_2'].std()\n",
    "print(\"\\nStandard deviation of column_2:\")\n",
    "print(std_dev_column_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e158c46-c13f-476d-a4a7-c36a3b37c05c",
   "metadata": {},
   "source": [
    "Q5. Replace the data present in the second row of column, ‘column_2’ by a string variable then find the\n",
    "mean of column, column_2.\n",
    "If you are getting errors in executing it then explain why.\n",
    "[Hint: To replace the data use df1.loc[] and equate this to string data of your choice.]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "To replace the data present in the second rows of column2 with a string variable  , we can use 'df1.loc[]'. \n",
    "However ,since 'column_2' contains numerical data replacing it with a string variable will result in an error when calculating the mean because the  column will contain a mixture of numerical and string values , which cannot be aggregated numerically "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43a13774-4816-4d80-8b44-1d1bceba3a94",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'float' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m df1 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame (np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m6\u001b[39m), columns\u001b[38;5;241m=\u001b[39m columns , index \u001b[38;5;241m=\u001b[39m indices)\n\u001b[1;32m      8\u001b[0m df1\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m2\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumn_2\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstring_data\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 10\u001b[0m mean_column_2 \u001b[38;5;241m=\u001b[39m \u001b[43mdf1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcolumn_2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean of column_2 after replacing data with string variable \u001b[39m\u001b[38;5;124m\"\u001b[39m, mean_column_2)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:11847\u001b[0m, in \u001b[0;36mNDFrame._add_numeric_operations.<locals>.mean\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11829\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[1;32m  11830\u001b[0m     _num_doc,\n\u001b[1;32m  11831\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturn the mean of the values over the requested axis.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11845\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  11846\u001b[0m ):\n\u001b[0;32m> 11847\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mNDFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:11401\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11393\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[1;32m  11394\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  11395\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m lib\u001b[38;5;241m.\u001b[39mNoDefault \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mno_default,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11399\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  11400\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m> 11401\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stat_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  11402\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnanops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnanmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m  11403\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:11353\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[0;34m(self, name, func, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11343\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m  11344\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing the level keyword in DataFrame and Series aggregations is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m  11345\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated and will be removed in a future version. Use groupby \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11348\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m  11349\u001b[0m     )\n\u001b[1;32m  11350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_by_level(\n\u001b[1;32m  11351\u001b[0m         name, axis\u001b[38;5;241m=\u001b[39maxis, level\u001b[38;5;241m=\u001b[39mlevel, skipna\u001b[38;5;241m=\u001b[39mskipna, numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only\n\u001b[1;32m  11352\u001b[0m     )\n\u001b[0;32m> 11353\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  11354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\n\u001b[1;32m  11355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/series.py:4816\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   4812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m   4813\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not implement \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4814\u001b[0m     )\n\u001b[1;32m   4815\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 4816\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelegate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:93\u001b[0m, in \u001b[0;36mdisallow.__call__.<locals>._f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 93\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;66;03m# we want to transform an object array\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;66;03m# ValueError message to the more typical TypeError\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;66;03m# e.g. this is normally a disallowed function on\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;66;03m# object arrays that contain strings\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(args[\u001b[38;5;241m0\u001b[39m]):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:155\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    153\u001b[0m         result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43malt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:418\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[0;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    416\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[0;32m--> 418\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n\u001b[1;32m    421\u001b[0m     result \u001b[38;5;241m=\u001b[39m _wrap_results(result, orig_values\u001b[38;5;241m.\u001b[39mdtype, fill_value\u001b[38;5;241m=\u001b[39miNaT)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:706\u001b[0m, in \u001b[0;36mnanmean\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m    703\u001b[0m     dtype_count \u001b[38;5;241m=\u001b[39m dtype\n\u001b[1;32m    705\u001b[0m count \u001b[38;5;241m=\u001b[39m _get_counts(values\u001b[38;5;241m.\u001b[39mshape, mask, axis, dtype\u001b[38;5;241m=\u001b[39mdtype_count)\n\u001b[0;32m--> 706\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m _ensure_numeric(\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_sum\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    708\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    709\u001b[0m     count \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, count)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:48\u001b[0m, in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     47\u001b[0m          initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'float' and 'str'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "columns = ['column_1', 'column_2', 'column_3', 'column_4', 'column_5', 'column_6']\n",
    "indices = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "df1 = pd.DataFrame (np.random.rand(6,6), columns= columns , index = indices)\n",
    "\n",
    "df1.loc[2,'column_2'] = 'string_data'\n",
    "\n",
    "mean_column_2 = df1['column_2'].mean()\n",
    "print(\"Mean of column_2 after replacing data with string variable \", mean_column_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbab3544-9fd0-46a9-97cb-88d092685582",
   "metadata": {},
   "source": [
    "When we try to execute this code , we will encounter an error when trying to calculate the mean of 'column_2' because it contains a mixture of numerical statistics such as mean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a93c328-3aea-419d-8e06-b14570a00f0c",
   "metadata": {},
   "source": [
    "Q6. What do you understand about the windows function in pandas and list the types of windows\n",
    "functions?\n",
    "\n",
    "In pandas , the window function are use d for performing calculations on a rolling window of data .These functions allow you to compute aggregate functions  like mean , sum , min ,max , etc , over a specified window of data points .This is particularly useful for time-series data analysis  , but it can also be applied to other types of data.\n",
    "\n",
    "The windows function in pandas are categorized into several types based on their functionality:\n",
    "\n",
    "1. Rolling Windows Functions : These functions compute aggregate statistics (eg . mean , sum , max ,min etc ) over a specified window of consecutive data points .\n",
    "2. Expanding Windows Functions:Expanding functions calculate statistics for all data points up to the current point , effectively \"expanding \" the window with each new data point \n",
    "\n",
    "3. Exponentially Weighted Windows Functions : These functions apply weights to data points based on their age or proximity to the current point , wiht more recent points recieving higher weights .\n",
    "\n",
    "4. Rolling Apply Functions : These Functions allows you to apply custom functions to rolling windows of data .\n",
    "\n",
    "Examples of specific window functions include rolling(), expanding(), ewm(), rolling_apply(), etc.\n",
    "\n",
    "- rolling(): Computes rolling statistics over a specified window size.\n",
    "- expanding(): Computes expanding statistics over the entire data range.\n",
    "- ewm(): Computes exponentially weighted moving statistics.\n",
    "- rolling_apply(): Applies a custom function over rolling windows.\n",
    "\n",
    "These window functions provide powerful tools for analyzing and transforming data, especially when dealing with time-series or sequential data. They allow for efficient calculation of various statistics and metrics over different window sizes, which can reveal trends, patterns, and anomalies in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea931fd6-f5f3-4b83-be45-11729bab76cd",
   "metadata": {},
   "source": [
    "Q7. Write a code to print only the current month and year at the time of answering this question.\n",
    "[Hint: Use pandas.datetime function]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e124125-9fda-43fa-aabe-e16ca4a383ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current month :2\n",
      "Current year :2024\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "current_date = pd.Timestamp.now()\n",
    "\n",
    "current_month = current_date.month \n",
    "current_year = current_date.year\n",
    "\n",
    "print(f\"current month :{current_month}\")\n",
    "print(f\"Current year :{current_year}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de2ebf0-c401-4977-beae-2558edec3d46",
   "metadata": {},
   "source": [
    "Q8. Write a Python program that takes in two dates as input (in the format YYYY-MM-DD) and\n",
    "calculates the difference between them in days, hours, and minutes using Pandas time delta. The\n",
    "program should prompt the user to enter the dates and display the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5301a01d-ceb1-436c-af62-da25d2a05aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def calculate_time_difference(start_date, end_date):\n",
    "    start_datetime = pd.to_datetime(start_date)\n",
    "    end_datetime = pd.to_datetime(end_date)\n",
    "    time_difference = end_datetime - start_datetime \n",
    "    days = time_difference.days \n",
    "    hours= time_difference.seconds // 3600\n",
    "    minutes =(time_differnce.seconds % 3600 )//60\n",
    "    return days ,hours ,minutes\n",
    "def main():\n",
    "    start_date = input (\"Enter the start date (YYYY-MM-DD):\")\n",
    "    end_date = input(\"Enter the end date(YYYY-MM-DD):\")\n",
    "    \n",
    "    days , hours ,minutes = calculate_time_difference(start_date , end_date)\n",
    "    \n",
    "    print(\"Time differnce\")\n",
    "    print(f\"Days:{days}\")\n",
    "    print(f\"hours:{hours}\")\n",
    "    print(f\"Minutes:{minutes}\")\n",
    "    \n",
    "    if __name__ == \"__main__\":\n",
    "        main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857482cf-adff-4243-8881-56244e4ba38c",
   "metadata": {},
   "source": [
    "Q9. Write a Python program that reads a CSV file containing categorical data and converts a specified\n",
    "column to a categorical data type. The program should prompt the user to enter the file path, column\n",
    "name, and category order, and then display the sorted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b233a6-7d3d-4609-8301-7e941164bb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "def convert_to_categorical (df , column_name , category_order):\n",
    "    df [column_name ]= pd.Categorical(df[column_name], categories = category_order , ordered = True )\n",
    "    return df\n",
    "\n",
    "def main ():\n",
    "    file_path = input (\"Enter the file path \")\n",
    "    \n",
    "    column_name = input (\"Enter the column name:\")\n",
    "    \n",
    "    category_order_str = input(\"Enter the category order seprated by commas :\")\n",
    "    category_order = category_order_str.split(' , ')\n",
    "    \n",
    "    try :\n",
    "        df = pd.read_csv(file_path)\n",
    "    except FileNotFoundError:\n",
    "        print(\"File not Found\")\n",
    "        return \n",
    "    df = convert_to_categorical(df , column_name , category_order)\n",
    "    \n",
    "    sorted_df = df.sort_Values(by=column_name)\n",
    "    \n",
    "    print(\"Sorted Data :\")\n",
    "    print(sorted_df)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1816374d-c835-4af7-b4a5-b19beca09c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def convert_to_categorical(df, column_name, category_order):\n",
    "    # Convert specified column to categorical\n",
    "    df[column_name] = pd.Categorical(df[column_name], categories=category_order, ordered=True)\n",
    "    return df\n",
    "\n",
    "def main():\n",
    "    # Prompt the user to enter the file path\n",
    "    file_path = input(\"Enter the file path: \")\n",
    "    \n",
    "    # Prompt the user to enter the column name\n",
    "    column_name = input(\"Enter the column name: \")\n",
    "    \n",
    "    # Prompt the user to enter the category order\n",
    "    category_order_str = input(\"Enter the category order separated by commas: \")\n",
    "    category_order = category_order_str.split(',')\n",
    "    \n",
    "    # Read the CSV file\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "    except FileNotFoundError:\n",
    "        print(\"File not found.\")\n",
    "        return\n",
    "    \n",
    "    # Convert specified column to categorical\n",
    "    df = convert_to_categorical(df, column_name, category_order)\n",
    "    \n",
    "    # Sort the data based on the specified column\n",
    "    sorted_df = df.sort_values(by=column_name)\n",
    "    \n",
    "    # Display the sorted data\n",
    "    print(\"Sorted Data:\")\n",
    "    print(sorted_df)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d93a9fe-6b4a-41f2-96b8-2cedadba0a15",
   "metadata": {},
   "source": [
    "This program prompts the user to enter the file path , column name , and category order .It then reads the CSV file , converts the specified column to a categorical data type with the given category order , sorts the data based on the specifieds column and finally displays the sorted data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8898e0a-3b95-4935-b7b9-25fc882b66a1",
   "metadata": {},
   "source": [
    "Q10. Write a Python program that reads a CSV file containing sales data for different products and\n",
    "visualizes the data using a stacked bar chart to show the sales of each product category over time. The\n",
    "program should prompt the user to enter the file path and display the chart."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f351255-b5f8-45a0-b5d1-2f2ec172bf80",
   "metadata": {},
   "source": [
    "we can create a python program to achieve this by using 'pandas' library for reading the CSV file and data manipulation , and 'matplotlib' library for data  visualization .Below is a python program that reads a CSV file containing sales , visualizes  the sales of each product category over time  using stacked bar chart , and display the chart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ac8d3b-b689-47bb-8dd7-3e980d94341b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_sales_data(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "    except FileNotFoundError :\n",
    "        print(\"File not found \")\n",
    "        return \n",
    "    \n",
    "    df ['Date']  = pd.to_datetime(df['Date'])\n",
    "    df['Year'] = df ['Date'].dt.year\n",
    "    df['Month'] = df ['Date'].df.month_name()\n",
    "    \n",
    "    sales_data = df.groupby(['Year','Month','Product_Category'])['Sales'].sum().unstack().fillna(0)\n",
    "    sales_data.plot(kind = ' bar' , stacked =True ,figsize =(10, 6))\n",
    "    plt.title('Sales of Each Product Category Over time ')\n",
    "    plt.xlabel('Year-Month')\n",
    "    plt.ylabel('Total Sales')\n",
    "    plt.legend(title ='product Category', bbox_to_anchor=(1.05 , 1), loc ='upper left')\n",
    "    plt.xticks(rotation =45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def main():\n",
    "    file_path = input(\"Enter the file path :\")\n",
    "    \n",
    "    visualize_sales_data(file_path)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd93ae6a-ccb6-405b-ab78-783588c43b91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c0de48-bcaf-4ef3-be9b-270737aeeb9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
